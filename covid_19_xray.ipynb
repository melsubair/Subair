{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "covid-19-xray.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOfBjkFmVZ1QgUHpXN2aCNN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/melsubair/Subair/blob/master/covid_19_xray.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-uE_m1uP6Tfo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "07cd8102-372c-489e-faf2-377c0fa795e3"
      },
      "source": [
        "import os\n",
        "import cv2\n",
        "import scipy\n",
        "import warnings\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from random import shuffle\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from keras.optimizers import Adam, RMSprop\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import  Conv2D, MaxPooling2D, Activation, Flatten,Dense, Dropout, GlobalAveragePooling2D, BatchNormalization\n",
        "from keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4HPvQqX06yiy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Filter Warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wscepGxRDsll",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# File Paths\n",
        "input_path = \"../covid-19-xray/\""
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x3-paicSEBaZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "482058d4-8a12-4c6d-e00e-132f2cbb6c29"
      },
      "source": [
        "# File Contents\n",
        "for _set in ['train', 'test']:\n",
        "    normal = len(os.listdir(input_path + _set + '/normal'))\n",
        "    pneumonia = len(os.listdir(input_path + _set + '/pneumonia'))\n",
        "    print('The {} folder contains {} Normal and {} Pneumonia images.'.format(_set, normal, pneumonia))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The train folder contains 1336 Normal and 1615 Pneumonia images.\n",
            "The test folder contains 234 Normal and 390 Pneumonia images.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TJ4bIi5DGGpd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Preprocesing Data Function\n",
        "def preprocess_data(input_path, img_dims, batch_size):\n",
        "    \n",
        "    # Data Augmentation for Train & Test Images\n",
        "    train_datagen = ImageDataGenerator(\n",
        "        rescale = 1./255,\n",
        "        zoom_range = 0.2,\n",
        "        shear_range = 0.2,      \n",
        "        rotation_range = 40,\n",
        "        width_shift_range = 0.2,\n",
        "        height_shift_range = 0.2,\n",
        "        horizontal_flip = True,\n",
        "        fill_mode='nearest')\n",
        "\n",
        "    test_datagen = ImageDataGenerator(\n",
        "        rescale = 1./255)\n",
        "    \n",
        "    train_images = train_datagen.flow_from_directory(\n",
        "        directory = input_path + 'train', \n",
        "        target_size = (img_dims, img_dims), \n",
        "        batch_size = batch_size, \n",
        "        class_mode = 'binary')\n",
        "\n",
        "    test_images = test_datagen.flow_from_directory(\n",
        "        directory = input_path + 'test', \n",
        "        target_size = (img_dims, img_dims), \n",
        "        batch_size = batch_size, \n",
        "        class_mode = 'binary')\n",
        "\n",
        "    # I'm created these lists for make prediction on test image and showing confusion matrix.\n",
        "    train_labels = []\n",
        "    test_labels = []\n",
        "\n",
        "    for file_name in ['/normal/', '/pneumonia/']:\n",
        "        for img in (os.listdir(input_path + 'test' + file_name)):\n",
        "            img = cv2.imread(input_path + 'test' + file_name + img, cv2.IMREAD_GRAYSCALE)\n",
        "            img = cv2.resize(img, (img_dims, img_dims))\n",
        "            img = np.dstack([img, img, img])\n",
        "            img = img.astype('float32') / 255\n",
        "            if file_name == '/normal/':\n",
        "                label = 0\n",
        "            elif file_name == '/pneumonia/':\n",
        "                label = 1\n",
        "            train_labels.append(img)\n",
        "            test_labels.append(label)\n",
        "        \n",
        "    train_labels = np.array(train_labels)\n",
        "    test_labels = np.array(test_labels)\n",
        "    \n",
        "    return train_images, train_labels, test_images, test_labels"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SC-6qlfdHCz5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "abad8fca-3aa3-4ac2-e8ae-852d67290946"
      },
      "source": [
        "img_dims = 150\n",
        "epochs = 30\n",
        "batch_size = 2\n",
        "\n",
        "# Set Images&Labels for Train,Test\n",
        "train_images, train_labels, test_images, test_labels = preprocess_data(input_path, img_dims, batch_size)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 2951 images belonging to 3 classes.\n",
            "Found 624 images belonging to 3 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mc6T5rIdIIgF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 629
        },
        "outputId": "3f39b4cc-b1cb-40f9-8518-0b95ca61a041"
      },
      "source": [
        "# Create Model with KERAS library\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(32, (3,3), activation=\"relu\", input_shape=(img_dims,img_dims,3)))\n",
        "model.add(MaxPooling2D(2,2))\n",
        "model.add(Conv2D(64, (3,3), activation=\"relu\"))\n",
        "model.add(MaxPooling2D(2,2))\n",
        "model.add(Conv2D(128, (3,3), activation=\"relu\"))\n",
        "model.add(MaxPooling2D(2,2))\n",
        "model.add(Conv2D(256, (3,3), activation=\"relu\"))\n",
        "model.add(MaxPooling2D(2,2))\n",
        "model.add(Conv2D(256, (3,3), activation=\"relu\"))\n",
        "model.add(MaxPooling2D(2,2))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512, activation=\"relu\"))\n",
        "model.add(Dropout(0.6))\n",
        "model.add(Dense(1,activation=\"sigmoid\"))\n",
        "model.summary()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 148, 148, 32)      896       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 74, 74, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 72, 72, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 36, 36, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 34, 34, 128)       73856     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 17, 17, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 15, 15, 256)       295168    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 7, 7, 256)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 5, 5, 256)         590080    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2 (None, 2, 2, 256)         0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 512)               524800    \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 513       \n",
            "=================================================================\n",
            "Total params: 1,503,809\n",
            "Trainable params: 1,503,809\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MOFAlryvIYqP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Set Optimizer\n",
        "optimizer = Adam(lr = 0.0001)\n",
        "\n",
        "\n",
        "# Compile Model\n",
        "model.compile(\n",
        "    optimizer= optimizer,\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=['acc'])"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H9G06f4dIsmH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "250be47a-9d9b-494a-d5a5-57b3844d9eec"
      },
      "source": [
        "# Fit the Model\n",
        "history = model.fit_generator(\n",
        "            train_images,\n",
        "            steps_per_epoch = train_images.samples // batch_size, \n",
        "            epochs = epochs, \n",
        "            validation_data = test_images,\n",
        "            validation_steps = test_images.samples // batch_size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "1033/1475 [====================>.........] - ETA: 1:10 - loss: -587212966232.8719 - acc: 0.4562"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}